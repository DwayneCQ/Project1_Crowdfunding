---
title: "DM-Project1"
author: Anhong Chen 2016111063
output:
  html_document:
    df_print: paged
  pdf_document: default
---
# Loading Packages
```{r  message=FALSE}
library(randomForest)
library(tidyverse)
library(caret)
library(e1071)
library(adabag)
library(rpart)

```

# Loading File
```{r}
crowd = read.csv(file = '/Users/DwayneChen/Desktop/Project1_Crowdfunding/KickStarterData.csv', strip.white = TRUE)
head(crowd)
```
  
    
# (1) Exploring Data
First look at the data with respect to catogery

  
```{r}
crowd_1 <- select(crowd, "category_parent")
ggplot(data = crowd_1) + geom_bar(mapping = aes(x = category_parent), fill = "red") + theme(axis.text.x = element_text(size = 8, face = "bold", angle = 45))
```


  
We can see that *Film & Video* and *Music* have a overwhelmingly exceeding quantity than other categories. 

  

```{r}
crowd_2 <- select(crowd , 'category_parent', 'Successful') %>% table() %>% as.data.frame() %>% spread(., key = Successful, value = Freq)
names(crowd_2) <- c('category_parent', 'False', 'True')
succ_rate <- mutate(crowd_2, Rate = True / (False + True))
ggplot(data = succ_rate) + geom_point(mapping = aes(x = category_parent, y = Rate)) + theme(axis.text.x = element_text(size = 8, face = "bold", angle = 45)) 
```

  
We can see that though *Film & Video* is large in quantity of examples, it's successful rate is not as high as *Music*. Besides, the successful rate of *Dance* and *Theater* is fairly high with 0.9's successful rate. It was pretty out of my expectation, for I've thought that most of the crowd-funding programs are producing some advanced technology. 
Through these two graphs, we can easily say that if you cast an crowd-funding program in *Dance* and *Theater* you are just a step from success. 

-----

Then data with resepct to place. 
  

```{r}
crowd_3 <- select(crowd, 'Country', 'State') %>% filter(., Country != '#VALUE!' & State != '#VALUE!')
ggplot(data = crowd_3) + geom_bar(mapping = aes(x = State)) + theme(axis.text.x = element_text(size = 5, face = "bold", angle = 45))
```

  
I've plot the data of country too, but it has too many countries, leadning to an unreadable graph. So I've skip that step. Most of the programs come from the U.S.\. And above is the graph of the distribution with respect to states. 
  
It's clear that two states with most programs are *California * and *New York*, with is within expectation. 
  
```{r}
crowd_4 <- select(crowd , 'State', 'Successful') %>% table() %>% as.data.frame() %>% spread(., key = Successful, value = Freq)
names(crowd_4) <- c('State', 'False', 'True')
succ_rate_2 <- mutate(crowd_4, Rate = True / (False + True))
ggplot(data = succ_rate_2) + geom_point(mapping = aes(x = State, y = Rate)) + theme(axis.text.x = element_text(size = 5, face = "bold", angle = 45)) 
```

  
Except for the first two invalid column, there is not a significant difference in states. Only *Wyoming* is higher than others in over 90 percent of successful rate. 

----

Now let's look at some numeric indicators, including *Duration*, *Goal*, *Reward_count*.
  
```{r}
crowd_5 <- select(crowd, 'duration', 'goal', 'reward_count', 'Successful')
pairs(crowd_5[1:3], main = "Numeric indicaters", pch = 21, bg = c( "blue", "red")[factor(crowd_5$Successful)])
```
  
There seems to be too much overlapping. I'm not sure which color dominates in certain area. So I shall skip this part. 

  

# (2) Factors that influence the performance
From intuition, I came up with 3 hypothesis.

1. The longer the program is, the more it will be likely to succeed.
2. The more various the rewards are, the more it will be likely to succeed.
3. Programs based on the U.S. are more likely to succeed.
Now let's verify them one by one.

  

### Hypothesis I
```{r}
crowd_succ <- select(crowd, 'duration', 'Successful') %>% filter(., Successful == 'TRUE')
mean_succ <- mean(crowd_succ$duration)
crowd_fail <- select(crowd, 'duration', 'Successful') %>% filter(., Successful == 'FALSE')
mean_fail <- mean(crowd_fail$duration)
```

  

Mean duration of successful programs and failed ones are 37.12274 and 35.57016. There is a difference between two means, but is not far enough to determine a rule.

  

```{r}
crowd_6 <- select(crowd, 'duration', 'Successful')
ggplot(data = crowd_6, mapping = aes(x = Successful, y = duration)) + geom_violin()
```

  

From the graph, I almost thought that they were the same distrubution. The difference between two distributions lie only in variance and the range. Failed programs have a higher varience and successful programs have a wider range. Since then, I have enough evidence to determine that this hypothesis is false. 

  

-----

  

### Hypothesis II
```{r}
crowd_7 <- select(crowd, 'reward_count', 'Successful')
ggplot(crowd_7, aes(x = reward_count)) + geom_histogram(fill = "lightblue", colour = "black", binwidth = 1) + facet_grid(Successful ~ .)
```

  

There is actually a rule. In the graph of failed programs, there are a large number of programs that didn't have any reward, which means they want their backers to donate money to them, which is not crowd-funding at all. No wonder they fail. Since then, this hypothesis about relationship between reward amount and success is proved. 
  

----
### Hypothesis III
```{r}
crowd_us <- select(crowd, 'Country', 'Successful') %>% filter(., Country == 'United States')
crowd_nus <- select(crowd, 'Country', 'Successful') %>% filter(., Country != 'United States' & Country != '#VALUE!' & Country != '#NAME?')
table_us <- as.data.frame(table(crowd_us)) %>% spread(., key = Successful, value = Freq)
table_nus <- as.data.frame(table(crowd_nus)) %>% spread(., key = Successful, value = Freq)
us_rate <- sum(table_us[3])/(sum(table_us[2]) + sum(table_us[3]))
nus_rate <- sum(table_nus[3])/(sum(table_nus[2]) + sum(table_nus[3]))
```

  

The successful rate in the U.S. is 0.756 while in other countries is 0.82, which is completly out of my expectation. Maybe it's because programs in the U.S. are much more than the other countries, which lead to a relatively unsatisfied quality. Now, this hypothesis is proved to be false. What a sad story. 

# (3) Models predicting the statues of crowd-funding program

```{r}
crowd_c <- crowd[, c(-1, -2, -3, -4, -11, -12, -13, -19, -20, -23, -24, -25)]
inTrain<-createDataPartition(y=crowd_c$Successful, p=0.7, list=FALSE)
train<-crowd_c[inTrain,]
test<-crowd_c[-inTrain,]
train$Successful <- as.factor(train$Successful)
adaboost<-boosting(Successful~., data=train,boos=FALSE,mfinal=20,coeflearn='Breiman')
adaboost$importance
```

The most related features are *endDate*, *location*, *backers*, *category*, *goal*. But backers are not known forehand. 


### Logistic Regression
```{r}
lr <- glm(Successful~endDate+location+category+goal, data = train, family="binomial")
pred_lr<-ifelse(predict(lr, test[,-16])>0.5,1,0)
acc_lr <- confusionMatrix(as.factor(pred_lr), as.factor(test$Successful))
```

### SVM
```{r}
model <- svm(Successful~endDate+location+category+goal, data = train)
pred_svm <- predict(model, test[,-16])
acc_SVM <- confusionMatrix(as.factor(pred_svm), as.factor(test$Successful))
acc_SVM
```


### Decesion Tree
```{r}
clf <- rpart(Successful~endDate+location+category+goal, data = train)
pred_dt <- predict(clf, test[,-16])
pred_dt <- ifelse(pred_dt[,2]>0.5, 'TRUE', 'FALSE')
acc_dt <- confusionMatrix(as.factor(pred_dt), as.factor(test$Successful))
acc_dt
```


### Naive Bayes

```{r}
NBfit <- naiveBayes(Successful~endDate+location+category+goal,laplace=0,data=train)
pred_nb <- predict(NBfit,test[,-16])
acc_nb <- confusionMatrix(as.factor(pred_nb), as.factor(test$Successful))
acc_nb
```

### Random Forest

```{r}
rf <- randomForest(Successful~endDate+location+category+goal, data=train, mtry=2, ntree=100)
pred_rf <- predict(rf, test[,-16])
acc_rf <- confusionMatrix(as.factor(pred_rf), as.factor(test$Successful))

```

From all the models, we can find that XXX achieved the best accuracy of XX. 

### Tuned XXX
```{r}

```

With further tuning, XXX achieved a better results of accuracy of XX. Because of the constraint of device, I can't do more with this problem. It takes too much time to run a model.

# (4) Models predicting the amount of fund

### Linear Regression

```{r}

```

### Regression Tree

```{r}

```

# (5) Suggestions for fundraisers

# (6) Suggestions for investers

